[TOC]

# 1. EPT

EPT即Extended Page Tables(扩展页表)的缩写，加速从虚拟机地址至主机物理地址的转换过程。
- 客户机虚拟地址（Guest Virtual Address, GVA)
- 客户机物理地址（Guest Physical Address, GPA）
- 宿主机物理地址（Host Physical Address, HPA）

CPU访问内存：
- GVA -> GPA -> HPA 需要两次地址转换
- GVA -> HPA（利用影子页表Shadow Page Tables 需要一次地址转换）
- GVA -> HPA（Intel的CPU提供了EPT技术，直接在硬件上实现GVA->HPA地址转换，从而替换影子页表）

## 1.1 查看硬件是否支持EPT
```
#> cat /proc/cpuinfo | grep ept
```

## 1.2 查看KVM是否启用EPT
```
#> cat /sys/module/kvm_intel/parameters/ept
```

# 2. VPID

VPID：提升虚拟机实时迁移（Live Migration）效率。

虚拟处理器标识(VPID，Virtual Processor IDs)是对现在的CPUID功能的一个强化，因为在每个CPU中都有一个TLB，
用来缓存虚拟地址到物理地址的转换表，而每个虚拟机都有自己的虚拟CPU来对应。所以，在进行迁移时要进行TLB的转存和清除。

而VPID则会跟踪每个虚拟CPU的TLB，当进行虚拟机迁移或VM Entry与VM Exit时，VMM可以动态的分配非零虚拟处理器的ID来迅速匹配(0 ID给VMM自己使用)，
从而避免了TLB的转存与清除的操作，节省了系统开销，并提高了迁移速度，同时也降低对系统性能的影响。

## 2.1 查看硬件是否支持VPID
```
#> cat /proc/cpuinfo | grep vpid
```

## 2.2 查看KVM是否启用VPID
```
#> cat /sys/module/kvm_intel/parameters/vpid
```

# 3. flexpriority

FlexPriority：优化虚拟机中断请求。

在传统服务器上，只装有一个操作系统，而这个操作系统享有这个服务器的所有资源，包括CPU。而CPU在处理任务时，有一个重要的功能就是中断请求，它用来在不同任务间根据优先级进行切换。但是，当服务器通过虚拟化生成若干个虚拟机时，这个服务器中实际上就有若干个“自以为独享硬件平台”的操作系统，而此时虚拟机相对于CPU来说是一个个大的“任务”，如何处理好这些虚拟机的中断请求，对于虚拟化的效率就至关重要。

英特尔处理器中都会一个专门的中断控制器，即Advanced Programmable Interrupt Controller (APIC，高级可编程中断控制器)，它通过一个任务优先寄存器(TPR，Task Priority Register)，以优先级的顺序来管理中断请求。

FlexPriority则将TPR复制，虚拟机可以自行修改TPR的副本，并直接与CPU打交道，而不再需要VMM的干预，多费一道手续，
从而提高了虚拟化性能。

## 3.1 查看硬件是否支持flexpriority
```
#> cat /proc/cpuinfo | grep flexpriority
```

## 3.2 查看KVM是否启用flexpriority
```
#> cat /sys/module/kvm_intel/parameters/flexpriority
```

# 4. Huge Page

大页（Huge Page）：x86_64架构的CPU默认使用4KB大小的内存页面，Kernel支持2MB大小的大页（huge page）。如果在系统中使用了huge page，
则内存页的数量会减少，从而需要更少的页表（page table），节约了页表所占用的内存数量，并且所需的地址转换也减少了，
TLB缓存失效的次数也减少了，从而提供了内存访问性能。另外，由于地址转换所需要的信息一般存在CPU的缓存中，huge Page的
使用让地址转换的信息减少，从而减少了CPU缓存的使用，减轻了CPU缓存的压力，让CPU缓存能更多地用于应用程序的数据缓存，
也能够在整体上提升系统的性能。


qemu-kvm提供了：

"-mem-path FILE"参数用于使用huge page。

"-mem-prealloc"参数可以让宿主机在启动客户机时就全部分配好客户机的内存。
- 优点：客户机的内存访问速度更快。
- 缺点：客户机启动时就得到了所有的内存，从而让宿主机的内存一次性减少（而不是按需动态内存分配）。
		
1. 检查默认内存页面大小和内存使用情况
```
#> getconf PAGESIZE
#> cat /proc/meminfo
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
DirectMap4k:      277332 kB
DirectMap2M:    11161600 kB
DirectMap1G:    258998272 kB
```
2. 挂在hugetblfs文件系统
```
#> mount -t hugetlbfs hugetlbfs /dev/hugepages
```
3. 设置hugepage数量
```
#> sysctl vm.nr_hugepages=1024
```
4.客户机使用hugepage
```
--mem-path=/dev/hugepages
```
总体来说，对于内存访问密集型的应用，在KVM客户机中使用huge page是可以较明显地提供客户机性能，不过，
它也有一个缺点，使用huge page的内存不能被换出（swap out），也不能使用ballooning方式自动增长。

# 5. 内存过载使用

KVM中内存也是允许过载使用（over-commit），KVM能够让分配给客户机的内存总数大于实际可用的物理内存总数。
有三种方式实现内存过载使用：
- 内存交换（swapping）：用交换空间（swap space）来弥补内存的不足。
- 气球（ballooning）：通过virio——balloon驱动来实现宿主机Hypervisor和客户机之间的协作。
- 页共享（page sharing）：通过KSM（Kernel Samepage Merging）合并多个客户机进程使用的相同内存页。

用swapping方式来让内存过载使用，要求有足够的交换空间（swap space）来满足所有的客户机进程和宿主机中
其他进程所需内存。交换空间通常是由磁盘分区来实现的，其读写速度比物理内存慢的很多，性能并不好。过多
内存过载使用也可能导致系统稳定性降低。


# 6. 配置参数

-m msgs 参数设置客户机的内存为msgs MB大小，支持"M"或"G"后缀指定内存分配单位(defalut=128MB)。
